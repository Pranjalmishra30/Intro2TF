{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Improved Fashion-MNIST.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oVOnmq-mqiRT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_images,train_labels),(test_images,test_labels) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "nKmF3ZI8quor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(train_images[100],cmap='gray')\n",
        "print(train_labels[100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "fcjNdAkPttvY",
        "outputId": "96d70fa0-299a-48cd-f794-1ef72ab3e627"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAASRElEQVR4nO3dbYxUZZYH8P8RAXmTd1oEdhlGjcFJVlaCxDWr62QngCaIMWT4sKIh22MEnTF8WOJq8MskRndmdj5sJulZZWAzy2QSYCHGFxAnEWKY0CIioIO82vLSvImANDQvZz/0hfRg3XOaeqrqVnP+v4R09z31VJ2+1YdbVec+9xFVBRFd/24oOgEiqg0WO1EQLHaiIFjsREGw2ImCuLGWDyYi/Oi/xnr06GHGhwwZkjT+woULZvzYsWO5MXaCqkNVpdT2pGIXkSkAfg2gB4D/VtVXUu4vKpGSz80VKUUxcOBAMz5z5kwz3r9/fzN+4sQJM75kyZLcWFtbmzmWKqvsl/Ei0gPAfwGYCmA8gFkiMr5SiRFRZaW8Z58EYKeq7lbVdgB/ADC9MmkRUaWlFPsoAC2dfv4q2/ZXRKRRRJpFpDnhsYgoUdU/oFPVJgBNAD+gIypSypF9P4AxnX4enW0jojqUUuwbAdwuIt8TkV4AfgxgVWXSIqJKk5S2johMA/Cf6Gi9vaGqP3duz5fxVTBnzpzc2OTJk82x27dvN+MbN2404/fdd58Zv/fee3NjGzZsMMe+9tprZtxjnSNw8eLFpPuuZ1Xps6vqWwDeSrkPIqoNni5LFASLnSgIFjtRECx2oiBY7ERBsNiJgkjqs1/zgwXts6dOYX3uuefM+K233pobW7BggTm2SEuXLjXjZ8+eNeNPPfVU2Y99ww32ce7SpUtl33fR8vrsPLITBcFiJwqCxU4UBIudKAgWO1EQLHaiINh6y6S0x3r16mWObW9vN+NTpkwx4w8//LAZf/bZZ824pWfPnmb8/PnzZryaLazly5ebcW+K7KuvvpobS/296xlbb0TBsdiJgmCxEwXBYicKgsVOFASLnSgIFjtREOyzZ7w++4035l+IN7Un6/WTvZVWrWWTrby9sfWuudleUezJJ5/MjW3dutUc2533G/vsRMGx2ImCYLETBcFiJwqCxU4UBIudKAgWO1EQSau4Xk+88w2s5X+9PvtLL71kxrds2WLGvZ5unz59cmNtbW3m2CKlzoVftGiRGZ83b15u7OmnnzbHerl1R0nFLiJ7AZwCcBHABVWdWImkiKjyKnFk/ydVPVqB+yGiKrr+XqsQUUmpxa4AVovIRyLSWOoGItIoIs0iYp/ITERVlfoy/n5V3S8iIwCsEZHPVfWDzjdQ1SYATUB9T4Qhut4lHdlVdX/29TCAFQAmVSIpIqq8sotdRPqJyIDL3wP4EQB73iARFabs+ewiMg4dR3Og4+3A/6rqz50xIV/Gv/POO2Z8xowZZtzrlVtzr+t53nW1l01+//33c2MPPfRQ0n3X85LPefPZy37Prqq7Afxd2RkRUU2x9UYUBIudKAgWO1EQLHaiIFjsREFcN1NcU5ZcBtJaKVOnTjXHHjhwwIynTkNNaa+l7rcUXnsq9XLOe/bsyY1Nnz7dHLty5Uoz7u23IvdrHh7ZiYJgsRMFwWInCoLFThQEi50oCBY7URAsdqIgulWf3eqFW5d6BvyebMqUxMcff9yMr1u3ruz7Bup7OmU1eb1qz86dO3Nj3hRXr89+8eLFsnIqEo/sREGw2ImCYLETBcFiJwqCxU4UBIudKAgWO1EQ3arPbvWTi+w1T5s2zYy//fbbVX38lH50EfOquyr1MtgtLS25scbGkquVXbFw4UIzfuLECTPeu3dvM2716b0efrnPGY/sREGw2ImCYLETBcFiJwqCxU4UBIudKAgWO1EQ3arPXqQ77rgjN7Z582ZzbOrc55RzCLy58KnXN08ZX+0e/+jRo3Nj3vUP7rzzTjO+YcMGM37u3DkzXgT3yC4ib4jIYRHZ2mnbEBFZIyJfZF8HVzdNIkrVlZfxvwMw5aptCwCsVdXbAazNfiaiOuYWu6p+AOD4VZunA1icfb8YwKMVzouIKqzc9+wNqnow+/4QgIa8G4pIIwD7RGQiqrrkD+hUVUUk95MWVW0C0AQA1u2IqLrKbb21ishIAMi+Hq5cSkRUDeUW+yoAs7PvZwOwr7tLRIWTLvRRlwJ4EMAwAK0AFgL4PwB/BPA3APYBmKmqV3+IV+q+kl7GL1u2LDd21113mWNbW1vN+LBhw8z4l19+mRs7evSoOdZbZ3z16tVmfMWKFWbcm1sd1dy5c3Nj48aNM8dazzfgP+feuRFDhw7NjX344Yfm2E2bNplxVS158oP7nl1VZ+WEfuiNJaL6wdNliYJgsRMFwWInCoLFThQEi50oCLf1VtEHS2y9vfvuu7mx2267zRzrXZbYm5J49uzZ3JjXtjt82D7nqFevXmbcy92axrp48eLcGAAsX77cjH/zzTdmvGfPnmbcaok+8sgjZY8FgPHjx5vxY8eO5cYaGnLP8AYAfP3112bce8769OljxgcPzp8oumrVKnPsE088YcbzWm88shMFwWInCoLFThQEi50oCBY7URAsdqIgWOxEQXSrS0lb0wa98wVOnz5txs+fP2/GrT78jh07zLFeL/r4cXt2cFtbmxkfPnx4buyZZ54xx1rTQAHg22+/NePepaot3nNy5swZM75///6yH9s79+Gmm24y4/v27TPjffv2NePW7+493+XikZ0oCBY7URAsdqIgWOxEQbDYiYJgsRMFwWInCqJb9dl79+6dGxswYIA5NnV+8s0335wb83rNR44cMePt7e1m3FteeNeuXbkxa043YP9egL9fvV54Ss/YW+rausYAYM8p957vW265JemxvfM+rMuLe3+r5eKRnSgIFjtRECx2oiBY7ERBsNiJgmCxEwXBYicKolv12a251V6v2ltC1+uLHjhwIDfmzYX34l6v2+uze/PlLd6c8oEDB5rxESNGmPHt27fnxrylrL3fy+vxW8sqe/t09+7dZtybr75nzx4zfs899+TGWlpazLHlco/sIvKGiBwWka2dtr0sIvtFZHP2b1pVsiOiiunKy/jfAZhSYvuvVPXu7N9blU2LiCrNLXZV/QCAfd0kIqp7KR/QzRORLdnL/NyFq0SkUUSaRaQ54bGIKFG5xf4bAN8HcDeAgwB+kXdDVW1S1YmqOrHMxyKiCiir2FW1VVUvquolAL8FMKmyaRFRpZVV7CIystOPMwBszbstEdUHt88uIksBPAhgmIh8BWAhgAdF5G4ACmAvgJ9UMccrrJ6wd51vr4/uzW8eOnRobsybz+71+L31173crDnj3rrzIiWX8r7Cu6a9t3671c/25sp7ffZ+/fqZ8UGDBuXGvP3i/b0MGzbMjHt/ExMn5r+rff75582x5XKLXVVnldj8ehVyIaIq4umyREGw2ImCYLETBcFiJwqCxU4URLea4mq1ebypmF5rzmtvWdNUvTaO13rz2jTWJbQBO3evreddEtnbLylxb5qo1xb0crem0HptOy/uPedebtaUbG9KdLl4ZCcKgsVOFASLnSgIFjtRECx2oiBY7ERBsNiJguhWfXbrcs7edEjv0sFeT9eKe5dE9pYe9nh9eut383Lzevhe3Ntv1vPijfX6zd54a794fy/efXuX4PZy37FjR27s888/N8eWi0d2oiBY7ERBsNiJgmCxEwXBYicKgsVOFASLnSiIbtVnP3bsWNXu25v3bfF6tqmXmvaknAPgxfv06WPGvXMIUn4379wI7xwAb7wl9Tn1rp9gLdPtXZ67XDyyEwXBYicKgsVOFASLnSgIFjtRECx2oiBY7ERBdKs++9at+cvAt7a2Jt2311e15ien9HO7Mt6Lp86Xt3jXhffOT7DiXo/fWzY5pYfvjfX2qXdd+ZaWFjO+a9cuM14N7pFdRMaIyJ9EZLuIbBORn2bbh4jIGhH5Ivs6uPrpElG5uvIy/gKA+ao6HsBkAHNFZDyABQDWqurtANZmPxNRnXKLXVUPquqm7PtTAD4DMArAdACLs5stBvBotZIkonTX9J5dRMYCmADgzwAaVPVgFjoEoCFnTCOAxvJTJKJK6PKn8SLSH8AyAD9T1ZOdY9rxSUrJT1NUtUlVJ6rqxKRMiShJl4pdRHqio9B/r6rLs82tIjIyi48EcLg6KRJRJbgv46Vj/uTrAD5T1V92Cq0CMBvAK9nXlVXJsJOPP/44N9bQUPJdxBUnT5404157y2oDeWOr3WKyplt6Y1OnwHotKqt1l7JMdldY+9Wbouotyey1aocPH27GP/nkEzNeDV15z/4PAP4FwKcisjnb9gI6ivyPIjIHwD4AM6uTIhFVglvsqroeQN7VEX5Y2XSIqFp4uixRECx2oiBY7ERBsNiJgmCxEwXRraa4Wr3ygwcP5sYA/5LIp06dMuMp01i9Xre3PLDXE7b6yV4/2Ot1F3kOQMrvncrbL17uo0aNMuNvvvnmNeeUikd2oiBY7ERBsNiJgmCxEwXBYicKgsVOFASLnSiIbtVnt2zcuNGMT5482Yx7PV2r7+r1e9va2sy4x8vNmlPu9Yu9+erenHIvN+scAm8uvJdbyqWkvXMbUi6RDfhLNq9bt86MVwOP7ERBsNiJgmCxEwXBYicKgsVOFASLnSgIFjtREFLNOcHfeTCRqj1Y3759zfi2bdvMeMq8ba+P7vWivbg3J90a7/WqPal99pS/L2+s16e3cvPu2+vDe9c3sNY4AIDHHnvMjKdQ1ZLJ88hOFASLnSgIFjtRECx2oiBY7ERBsNiJgmCxEwXRlfXZxwBYAqABgAJoUtVfi8jLAP4VwJHspi+o6lvVStRz5swZM75o0SIzPn/+fDO+Z8+e3FjKnG7A7/l6c6ctKXO+AaC9vd2Mp15XPuW+vfMPrPGp89kHDRpkxl988UUzbkn9e8nTlTMuLgCYr6qbRGQAgI9EZE0W+5Wq/kdZj0xENdWV9dkPAjiYfX9KRD4DYC93QUR155res4vIWAATAPw52zRPRLaIyBsiMjhnTKOINItIc1KmRJSky8UuIv0BLAPwM1U9CeA3AL4P4G50HPl/UWqcqjap6kRVnViBfImoTF0qdhHpiY5C/72qLgcAVW1V1YuqegnAbwFMql6aRJTKLXbp+GjwdQCfqeovO20f2elmMwBsrXx6RFQp7hRXEbkfwDoAnwK43Ed5AcAsdLyEVwB7Afwk+zDPuq/azae9Ru+9954ZnzBhQm7s3Llz5lhvOuSIESPMOJXn0KFDuTGvJehNmV61apUZnz17thmvprwprl35NH49gFKDC+upE9G14xl0REGw2ImCYLETBcFiJwqCxU4UBIudKIjr5lLS1fbAAw/kxsaOHWuOHTBggBn3LonsXc7Z6uN70yW9uJeb16/2xlu8v03v/AbrEt/euQ+tra1mfP369Wa8SLyUNFFwLHaiIFjsREGw2ImCYLETBcFiJwqCxU4URK377EcA7Ou0aRiAozVL4NrUa271mhfA3MpVydz+VlWHlwrUtNi/8+AizfV6bbp6za1e8wKYW7lqlRtfxhMFwWInCqLoYm8q+PEt9ZpbveYFMLdy1SS3Qt+zE1HtFH1kJ6IaYbETBVFIsYvIFBH5i4jsFJEFReSQR0T2isinIrK56PXpsjX0DovI1k7bhojIGhH5Ivtaco29gnJ7WUT2Z/tus4hMKyi3MSLyJxHZLiLbROSn2fZC952RV032W83fs4tIDwA7APwzgK8AbAQwS1W31zSRHCKyF8BEVS38BAwR+UcApwEsUdUfZNteBXBcVV/J/qMcrKr/Vie5vQzgdNHLeGerFY3svMw4gEcBPIkC952R10zUYL8VcWSfBGCnqu5W1XYAfwAwvYA86p6qfgDg+FWbpwNYnH2/GB1/LDWXk1tdUNWDqrop+/4UgMvLjBe674y8aqKIYh8FoKXTz1+hvtZ7VwCrReQjEWksOpkSGjots3UIQEORyZTgLuNdS1ctM143+66c5c9T8QO677pfVf8ewFQAc7OXq3VJO96D1VPvtEvLeNdKiWXGryhy35W7/HmqIop9P4AxnX4enW2rC6q6P/t6GMAK1N9S1K2XV9DNvh4uOJ8r6mkZ71LLjKMO9l2Ry58XUewbAdwuIt8TkV4AfgzAXhKzRkSkX/bBCUSkH4Afof6Wol4F4PISobMBrCwwl79SL8t45y0zjoL3XeHLn6tqzf8BmIaOT+R3Afj3InLIyWscgE+yf9uKzg3AUnS8rDuPjs825gAYCmAtgC8AvAdgSB3l9j/oWNp7CzoKa2RBud2PjpfoWwBszv5NK3rfGXnVZL/xdFmiIPgBHVEQLHaiIFjsREGw2ImCYLETBcFiJwqCxU4UxP8D6O6MGv2Ml68AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalisation\n",
        "train_images = train_images/255.\n",
        "test_images = test_images/255."
      ],
      "metadata": {
        "id": "Tb9meBQ3t3p7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Original DNN"
      ],
      "metadata": {
        "id": "FErZLgen9jN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Designing the model\n",
        "model = keras.Sequential([\n",
        "                          keras.layers.Flatten(),\n",
        "                          keras.layers.Dense(units=128,activation=tf.nn.relu),\n",
        "                          keras.layers.Dense(units=10,activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer=tf.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "model.fit(train_images,train_labels,epochs=5)\n",
        "print(\"EVALUATION\")\n",
        "model.evaluate(test_images,test_labels)"
      ],
      "metadata": {
        "id": "Rr6Sk-Qet9bO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e2d1ba5-832d-491e-c426-037fd49c792d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.4941 - accuracy: 0.8278\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3724 - accuracy: 0.8651\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3353 - accuracy: 0.8774\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3119 - accuracy: 0.8851\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2946 - accuracy: 0.8928\n",
            "EVALUATION\n",
            "313/313 [==============================] - 1s 1ms/step - loss: 0.3462 - accuracy: 0.8772\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.34616392850875854, 0.8772000074386597]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN\n"
      ],
      "metadata": {
        "id": "sbKP6SQM9xs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.ops.gen_nn_ops import Conv2D\n",
        "# Designing the model\n",
        "model = keras.Sequential([\n",
        "                          keras.layers.Conv2D(64,(3,3),activation='relu',input_shape=(28,28,1)),\n",
        "                          keras.layers.MaxPooling2D(2,2),\n",
        "                          keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
        "                          keras.layers.MaxPooling2D(2,2),\n",
        "                          keras.layers.Flatten(),\n",
        "                          keras.layers.Dense(units=128,activation=tf.nn.relu),\n",
        "                          keras.layers.Dense(units=10,activation=tf.nn.softmax)\n",
        "])\n",
        "model.summary()\n",
        "model.compile(optimizer=tf.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "model.fit(train_images,train_labels,epochs=5)\n",
        "print(\"EVALUATION\")\n",
        "model.evaluate(test_images,test_labels)"
      ],
      "metadata": {
        "id": "Mply5mEO0Ers",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffe3d01c-883b-4e6b-f33c-2b6447eda461"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 26, 26, 64)        640       \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 13, 13, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 11, 11, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 128)               204928    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 243,786\n",
            "Trainable params: 243,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.4415 - accuracy: 0.8400\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 82s 44ms/step - loss: 0.2980 - accuracy: 0.8913\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 81s 43ms/step - loss: 0.2523 - accuracy: 0.9063\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 82s 44ms/step - loss: 0.2182 - accuracy: 0.9189\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1909 - accuracy: 0.9292\n",
            "EVALUATION\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2891 - accuracy: 0.9034\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.28909382224082947, 0.9034000039100647]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Observations  \n",
        "1. 64 conv filters give slighly better accuracy and loss than 32  \n",
        "2. Removing last conv layer resulted in higher training acc. but lower validation acc.  "
      ],
      "metadata": {
        "id": "Y5y1LVUL_kE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BfjpC5P8Czu3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}